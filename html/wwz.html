<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.1" />
<title>wwz.wwz API documentation</title>
<meta name="description" content="A class for weighted wavelet z-transform analysis." />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>wwz.wwz</code></h1>
</header>
<section id="section-intro">
<p>A class for weighted wavelet z-transform analysis.</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># -*- coding: utf-8 -*-
#!/usr/bin/env python
&#34;&#34;&#34;A class for weighted wavelet z-transform analysis.
&#34;&#34;&#34;

from datetime import datetime
import numpy as np
import pickle
from scipy.interpolate import interp1d, splrep, splev
import sys

__author__ = &#34;Sebastian Kiehlmann&#34;
__credits__ = [&#34;Sebastian Kiehlmann&#34;, &#34;Walther Max-Moerbeck&#34;, &#34;Oliver King&#34;]
__license__ = &#34;GPL&#34;
__version__ = &#34;1.0&#34;
__maintainer__ = &#34;Sebastian Kiehlmann&#34;
__email__ = &#34;skiehlmann@mail.de&#34;
__status__ = &#34;Production&#34;

#==============================================================================
# CLASSES
#==============================================================================

class WWZ:
    &#34;&#34;&#34;A class for weighted wavelet z-transform analysis.&#34;&#34;&#34;

    #--------------------------------------------------------------------------
    def __init__(self, time=None, flux=None, flux_err=0):
        &#34;&#34;&#34;A class for weighted wavelet z-transform analysis.

        Parameters
        ----------
        time : array-like, optional
            Time stamps of the input data. The default is None.
        flux : array-like, optional
            Flux of the input data. The default is None.
        flux_err : array-like or float, optional
            Flux uncertainty of the input data. The default is 0.

        Returns
        -------
        None.

        Notes
        -----
        Setting the data during the instance initialization is optional. Data
        can be provided with the set_data() method.
        &#34;&#34;&#34;

        print(&#39;WWZ instance created.&#39;)

        if time is not None and flux is not None:
            self.set_data(time, flux, flux_err=flux_err)
        else:
            self._reset()

    #--------------------------------------------------------------------------
    def _reset(self):
        &#34;&#34;&#34;Reset all class attributes to None.

        Returns
        -------
        None.
        &#34;&#34;&#34;

        # data time, flux, and flux error:
        self.t = None
        self.x = None
        self.s_x = None

        # number of data points:
        self.n = 0

        # attributes filled by set_freq() and set_tau():
        self.linear_period = False
        self.freq = None
        self.tau = None
        self.len0 = None
        self.len1 = None

        # class attributes filled by transform method:
        self.snr_weights = None
        self.c = None
        self.v_x = None
        self.v_y = None
        self.n_eff = None
        self.wwz = None
        self.wwa = None
        self.wwz_sig = None
        self.wwa_sig = None
        self.wwz_pval = None
        self.wwa_pval = None
        self.n_sig = None

    #--------------------------------------------------------------------------
    def set_data(self, time, flux, flux_err=0.0, verbose=True):
        &#34;&#34;&#34;Provide data for the analysis.

        Parameters
        ----------
        time : array-like, optional
            Time stamps of the input data. The default is None.
        flux : array-like, optional
            Flux of the input data. The default is None.
        flux_err : array-like or float, optional
            Flux uncertainty of the input data. The default is 0.
        verbose : bool, optional
            Turns printing of information on or off. The default is True.

        Returns
        -------
        None.

        Notes
        -----
        When new data is provided all class attributes that may contain the
        results of an earlier analysis will be reset to None.
        &#34;&#34;&#34;

        self._reset()

        # data time, flux, and flux error:
        self.t = np.asarray(time)
        self.x = np.asarray(flux)
        self.s_x = np.asarray(flux_err)

        # number of data points:
        self.n = len(time)

        if verbose:
            print(&#39;Data stored.&#39;)

    #--------------------------------------------------------------------------
    def get_period_lims(self, p_min_factor=4., p_max_factor=5.):
        &#34;&#34;&#34;Get suggested limits for the periods.

        Parameters
        ----------
        p_min_factor : float, optional
            If p_min is None, p_min is calculated as the median difference
            between time steps multiplied with this factor.
        p_max_factor : float, optional
            If p_max is None, p_max is calculated as the total time of the data
            devided by this factor.

        Returns
        -------
        p_min : float
            Suggested minimum period.
        p_max : float
            Suggested maximum period.
        &#34;&#34;&#34;

        p_min = np.round(np.median(np.diff(self.t)) * p_min_factor)
        p_max = np.round((self.t[-1] - self.t[0]) / p_max_factor)

        return p_min, p_max

    #--------------------------------------------------------------------------
    def get_freq(
            self, p_min=None, p_max=None, n_bins=100, diff=None,
            linear_period=False, p_min_factor=4., p_max_factor=5.):
        &#34;&#34;&#34;Create a range of frequencies for the analysis.

        Parameters
        ----------
        p_min : float, optional
            Minimum period. If provided, this shorest period will define the
            highest frequency. If None, the shortest period will be determined
            by the median of the time difference between data points. The
            default is None.
        p_max : float, optional
            Maximum period. If provided, this largest period will define the
            lowest frequency. If None, the largest period will be determined
            by the total duration of the data. The default is None.
        n_bins : int, optional
            Number of frequencies. The default is 100.
        diff : float, optional
            Sets the difference between frequency bins. The number of bins will
            be calculated accordingly. If linear_period=True, this sets the
            difference between periods. If diff is set, this overwrites any
            input to n_bins. The default is None.
        linear_period : bool, optional
            If False, the frequencies will be distributed in equal steps. If
            True, the frequencies are chosen such that the corresponding
            periods are distributed in equal steps. The default is False.
        p_min_factor : float, optional
            If p_min is None, p_min is calculated as the median difference
            between time steps multiplied with this factor.
        p_max_factor : float, optional
            If p_max is None, p_max is calculated as the total time of the data
            devided by this factor.

        Raises
        ------
        ValueError
            Error is raise when neither n_bins nor diff is provided.

        Returns
        -------
        freq : numpy.ndarray
            One dimensional array of frequencies.
        &#34;&#34;&#34;

        p_min_suggested, p_max_suggested =  self.get_period_lims(
                p_min_factor=p_min_factor, p_max_factor=p_max_factor)

        if p_min is None:
            p_min = p_min_suggested
        elif p_min &lt; p_min_suggested:
            print(&#39;WARNING: p_min is shorter than {0} &#39;.format(p_min_factor),
                  &#39;times the median time step of the data.\np_min should &#39;,
                  &#39;not be shorter than {0}.\n&#39;.format(p_min_suggested))

        if p_max is None:
            p_max = p_max_suggested
        elif p_max &gt; p_max_suggested:
            print(&#39;WARNING: p_max is larger than the maximum time range&#39;,
                  &#39;of the data devided by {0}.\np_min &#39;.format(p_max_factor),
                  &#39;should not be larger than {0}.\n&#39;.format(p_max_suggested))

        freq_min = 1. / p_max
        freq_max = 1. / p_min

        if linear_period:
            if diff is not None:
                period = np.arange(p_min, p_max, diff)

            elif isinstance(n_bins, int):
                period = np.linspace(p_min, p_max, n_bins)
                diff = period[1] - period[0]

            else:
                raise ValueError(&#34;Either n_bins or diff needs to be set.&#34;)

            freq = 1. / period
            freq = freq[::-1]

        else:
            if diff is not None:
                freq = np.arange(freq_min, freq_max, diff)

            elif isinstance(n_bins, int):
                freq = np.linspace(freq_min, freq_max, n_bins)
                diff = freq[1] - freq[0]

            else:
                raise ValueError(&#34;Either n_bins or diff needs to be set.&#34;)

        print(&#39;Linear range of frequencies created with&#39;)
        print(&#39;Shortest period:       {0:10.2e}&#39;.format(p_min))
        print(&#39;Longest period:        {0:10.2e}&#39;.format(p_max))
        if linear_period:
            print(&#39;Period interval:       {0:10.2e}&#39;.format(diff))
        else:
            print(&#39;Period interval:       non-linear&#39;)
        print(&#39;Lowest frequency:      {0:10.2e}&#39;.format(freq_min))
        print(&#39;Highest frequency:     {0:10.2e}&#39;.format(freq_max))
        if linear_period:
            print(&#39;Frequency interval:    non-linear&#39;)
        else:
            print(&#39;Frequency interval:    {0:10.2e}&#39;.format(diff))
        print(&#39;Number of frequencies: {0:10d}\n&#39;.format(freq.size))

        return freq

    #--------------------------------------------------------------------------
    def get_tau(self, t_min=None, t_max=None, n_div=8, n_bins=None, dtau=None):
        &#34;&#34;&#34;Create a range of taus (time points) for the analysis.

        Parameters
        ----------
        t_min : float, optional
            Earliest time point. If not provided, will be the first data point.
            The default is None.
        t_max : float, optional
            Latest time point. If not provided, will be the last data point.
            The default is None.
        n_div : int, optional
            The total time of the data will be devided by n_div. The result is
            converted to the nearest integer. This sets the number of time
            bins. A larger n_div will result in fewer time bins, and vice
            versa. The default is 8.
        n_bins : int, optional
            Number of time bins. If n_bins is set, this overwrites any input to
            n_div. The default is None.
        dtau : float, optional
            Sets the difference between time bins. The number of bins will
            be calculated accordingly. If diff is set, this overwrites any
            input to n_bins and n_div. The default is None.

        Raises
        ------
        ValueError
            Error is raise when neither n_bins nor diff is provided.

        Returns
        -------
        freq : numpy.ndarray
            One dimensional array of frequencies.
        &#34;&#34;&#34;

        t_min = self.t[0]
        t_max = self.t[-1]

        if dtau is not None:
            tau = np.arange(t_min, t_max, dtau)
            n_bins = tau.size

        elif isinstance(n_bins, int):
            tau = np.linspace(t_min, t_max, n_bins)
            dtau = tau[1] - tau[0]

        elif isinstance(n_div, int):
            n_bins = int((t_max - t_min) / n_div)
            tau = np.linspace(t_min, t_max, n_bins)
            dtau = tau[1] - tau[0]

        else:
            raise ValueError(&#34;Either n_div, n_bins, or dtau needs to be set.&#34;)

        print(&#39;Linear range of tau (time points) created with&#39;)
        print(&#39;Earliest time:         {0:10.1f}&#39;.format(t_min))
        print(&#39;Latest time:           {0:10.1f}&#39;.format(t_max))
        print(&#39;Time interval:         {0:10.1f}&#39;.format(dtau))
        print(&#39;Points in time:        {0:10d}\n&#39;.format(n_bins))

        return tau

    #--------------------------------------------------------------------------
    def set_freq(self, freq, verbose=True):
        &#34;&#34;&#34;Set the frequencies for the analysis.

        Parameters
        ----------
        freq : array-like
            A range of frequencies at which the WWZ transform will be
            calculated.
        verbose : bool, optional
            Turns printing of information on or off. The default is True.

        Returns
        -------
        None.

        Notes
        -----
        It is recommended to use the get_freq() method to create the array of
        frequencies.
        &#34;&#34;&#34;

        self.freq = np.asarray(freq)
        self.len1 = freq.size

        # check if frequencies are linear in period space:
        dperiod = np.diff(1. / freq)
        self.linear_period = np.all(np.isclose(dperiod, dperiod[0]))

        if verbose:
            print(&#39;Frequencies set.&#39;)

    #--------------------------------------------------------------------------
    def set_tau(self, tau, verbose=True):
        &#34;&#34;&#34;Set the taus (time points) for the analysis.

        Parameters
        ----------
        tau : array-like
            A range of time points at which the WWZ transform will be
            calculated.
        verbose : bool, optional
            Turns printing of information on or off. The default is True.

        Returns
        -------
        None.

        Notes
        -----
        It is recommended to use the get_tau() method to create the array of
        taus.
        &#34;&#34;&#34;

        self.tau = np.asarray(tau)
        self.len0 = tau.size

        if verbose:
            print(&#39;Tau (time points) set.&#39;)

    #--------------------------------------------------------------------------
    def transform(self, c=1./(8.*np.pi**2), snr_weights=False, verbose=0):
        &#34;&#34;&#34;Perform the WWZ transform as defined in [1].

        Parameters
        ----------
        c : float, optional
            The window decay parameter. See [1], Sec. 1 for a description.
            The default is 1./(8.*np.pi**2).
        snr_weights : bool, optional
            If True, the fluxes are additionally weighted by their
            corresponding signal-to-noise ratio, derived from the provided
            flux uncertainties. The default is False.
        verbose : int, optional
            Defines how much information is printed out. 0, no information is
            printed. 1, some information is printed. 2, all information is
            printed. The default is 0.

        Returns
        -------
        bool
            Returns True, if the analysis was performed succesfully. False,
            otherwise.

        References
        ----------
        [1] Foster, 1996
            https://ui.adsabs.harvard.edu/abs/1996AJ....112.1709F/abstract

        &#34;&#34;&#34;

        if self.freq is None or self.tau is None:
            print(&#39;Frequencies and/or taus are not set. Analysis aborted.&#39;)
            return False

        if verbose:
            t_start = datetime.now()
            print(&#39;Starting the WWZ transform..&#39;)

        self.c = c
        self.snr_weights = snr_weights

        if verbose &gt; 1:
            print(&#39;Setting frequency-tau-grid..&#39;)

        # create the wavelet grid:
        freq, tau = np.meshgrid(2*np.pi*self.freq, self.tau)
        # freq: the frequencies at which to evaluate the wavelet
        # tau: the delays over which to calculate the wavelet

        if verbose &gt; 1:
            print(&#39;Creating weights..&#39;)

        # arrays which are used but not returned
        s = np.zeros((3, 3, self.len0, self.len1), dtype=np.float64)
        s_inv = np.zeros((3, 3, self.len0, self.len1), dtype=np.float64)
        w = np.zeros((self.n, self.len0, self.len1), dtype=np.float64)

        p1=0.0
        p2=0.0
        p3=0.0
        w_d=0.0
        w_d_s=0.0
        v_x=0.0
        v_x_s=0.0
        v_y=0.0
        v_y_s=0.0

        if verbose &gt; 1:
            print(&#39;Calculating projections and scattering matrix..&#39;)

        for a in np.arange(0, self.n):
            # weights:
            w[a] = np.exp(-self.c * freq**2 * (self.t[a] - tau)**2)

            if snr_weights:
                w[a] *= np.sqrt(self.x[a]**2 / self.s_x[a]**2)

            w_d += w[a]
            w_d_s += w[a]**2

            # weighted variation of the data:
            v_x += w[a] * self.x[a]
            v_x_s += w[a] * self.x[a]**2

            # trial functions:
            t1 = 1.0
            t2 = np.cos(freq * (self.t[a] - tau))
            t3 = np.sin(freq * (self.t[a] - tau))

            # projections:
            p1 += w[a] * t1 * self.x[a]
            p2 += w[a] * t2 * self.x[a]
            p3 += w[a] * t3 * self.x[a]

            # s-matrix elements:
            s[0,0] += w[a] * t1 * t1
            s[1,0] += w[a] * t2 * t1
            s[0,1] += w[a] * t1 * t2
            s[2,0] += w[a] * t3 * t1
            s[0,2] += w[a] * t1 * t3
            s[1,1] += w[a] * t2 * t2
            s[2,1] += w[a] * t3 * t2
            s[1,2] += w[a] * t2 * t3
            s[2,2] += w[a] * t3 * t3

        # the projections of the trial functions onto the data are:
        p1 /= w_d
        p2 /= w_d
        p3 /= w_d
        # the scattering matrix elements are:
        s /= w_d

        if verbose &gt; 1:
            print(&#39;Inverting scattering matrix..&#39;)

        # invert scattering matrix:
        for m in np.arange(0, self.len0):
            for n in np.arange(0, self.len1):
                s_inv[:,:,m,n] = np.linalg.inv(s[:,:,m,n])

        if verbose &gt; 1:
            print(&#39;Calculating model coefficients..&#39;)

        # model coefficients:
        y1 = s_inv[0,0] * p1 + s_inv[0,1] * p2 + s_inv[0,2] * p3
        y2 = s_inv[1,0] * p1 + s_inv[1,1] * p2 + s_inv[1,2] * p3
        y3 = s_inv[2,0] * p1 + s_inv[2,1] * p2 + s_inv[2,2] * p3

        if verbose &gt; 1:
            print(&#39;Calculating elements of transform..&#39;)

        # calculate elements of the transform:
        for a in np.arange(self.n):
            ya = y1 * 1.0 + y2 * np.cos(freq * (self.t[a] - tau)) \
                    + y3 * np.sin(freq * (self.t[a] - tau))
            v_y += w[a] * ya
            v_y_s += w[a] * ya**2

        if verbose &gt; 1:
            print(&#39;Calculating WWZ and WWA..&#39;)

        self.v_x = (v_x_s / w_d) - (v_x / w_d)**2
        self.v_y = (v_y_s / w_d) - (v_y / w_d)**2
        self.n_eff = w_d**2 / w_d_s
        self.wwz = ((self.n_eff - 3.) * self.v_y) \
                / (2. * (self.v_x - self.v_y))
        self.wwa = np.sqrt(y2**2 + y3**2)

        if verbose:
            t_used = datetime.now() - t_start
            print(&#39;Finished in&#39;, t_used)

        return True

    #--------------------------------------------------------------------------
    def save(self, filename):
        &#34;&#34;&#34;Save the class instance in a python pickle file.

        Parameters
        ----------
        filename : str
            Filename under which the class instance is saved.

        Returns
        -------
        None.
        &#34;&#34;&#34;

        with open(filename, mode=&#39;wb&#39;) as f:
            pickle.dump(self, f)

    #--------------------------------------------------------------------------
    def load(self, filename):
        &#34;&#34;&#34;Load a saved WWZ class instance from a python pickle file.

        Parameters
        ----------
        filename : str
            File name of the pickle file.

        Returns
        -------
        WWZ-type
            Returns a instance of WWZ.
        &#34;&#34;&#34;

        with open(filename, mode=&#39;rb&#39;) as f:
            return pickle.load(f)

    #--------------------------------------------------------------------------
    def estimate_significance(self, simulations, append=False):
        &#34;&#34;&#34;Monte Carlo based significance estimation.

        Parameters
        ----------
        simulations : list
            Each list entry is one simulation that will be analysed in the same
            way as the real data. The data structure for each simulation need
            to be the following. A list, tuple, or numpy.ndarray, where the
            first element/row contains the time steps, the second element/row
            contains the signal. Optionally a third element contains the
            corresponding uncertainties. The uncertainty can also be a single
            value.
        append : bool, optional
            If False, currently available significance estimations will be
            discarded and overwritten with the new analysis. If True, the
            analysis of the new simulations will be added to the existing ones.
            The default is False.

        Returns
        -------
        bool
            True, if the analysis finished. False, if the analysis was aborted.

        Notes
        -----
        When new simulations are appended, i.e. append=True, it is up to the
        user to ensure that the new simulations are independent of the previous
        ones. This method does not track simulations and cannot guarantee that
        repetitions are discarded.
        &#34;&#34;&#34;

        if self.wwz is None:
            print(&#39;Analyse data first. Aborted!&#39;)
            return False

        # reset/initialize simulation results:
        if not append or self.wwz_sig is None:
            self.wwz_sig = np.zeros(shape=self.wwz.shape)
            self.wwa_sig = np.zeros(shape=self.wwa.shape)
            self.n_sig = 0

        # prepare WWZ instance for analysis of simulations:
        analyser = WWZ()

        n = len(simulations)
        t_start = datetime.now()
        print(&#39;Starting analysis of simulations at&#39;, t_start)

        # iterate through simulations:
        for i, simulation in enumerate(simulations):
            sys.stdout.write(&#39;\rProgress: {0:d} of {1:d}. {2:.1f}%&#39;. format(
                    i+1, n, i*100./n))

            # extract simulation data:
            time = simulation[0]
            flux = simulation[1]
            try:
                flux_err = simulation[2]
            except:
                flux_err = 0

            # analyse simulation data:
            analyser.set_data(time, flux, flux_err, verbose=False)
            analyser.set_freq(self.freq, verbose=False)
            analyser.set_tau(self.tau, verbose=False)
            analyser.transform(
                    c=self.c, snr_weights=self.snr_weights, verbose=0)
            self.wwz_sig += analyser.wwz &gt; self.wwz
            self.wwa_sig += analyser.wwa &gt; self.wwa
            self.n_sig += 1

        self.wwz_pval = self.wwz_sig / self.n_sig
        self.wwa_pval = self.wwa_sig / self.n_sig

        t_used = datetime.now() - t_start
        print(&#39;\rFinished in&#39;, t_used)

        return True

    #--------------------------------------------------------------------------
    def _find_peaks(self, x, y, threshold, sampling=10):
        &#34;&#34;&#34;Find peaks above a given threshold along a 1d-signal y(x).

        Parameters
        ----------
        x : numpy.ndarray
            Positional data of the signal, e.g. frequency or period.
        y : numpy.ndarray
            Signal, e.g. WWZ, WWA, or p-value along one time bin.
        threshold : float
            Defines the noise level. Only signals above this threshold are
            detected.
        sampling : int
            The interpolated signal is evalued at n times the sampling of the
            original data, where n is set by this number.

        Returns
        -------
        peak_x : list
            Peak positions.
        peak_y : list
            Peak signal strenghts.

        Notes
        -----
        This method uses spline interpolation to improve the estimation of the
        peak position and signal. Multiple peaks are identified recursively
        starting with the strongest peak.
        &#34;&#34;&#34;

        if np.all(y &lt; threshold) or x.size &lt;= 3:
            return [], []

        # the spline fit requires an increasing order of x,
        # reverse order, if x is decreasing:
        if x.size &gt; 1 and x[0] &gt; x[1]:
            x = x[::-1]
            y = y[::-1]

        # spline interpolation:
        tck = splrep(x, y, s=0)
        n = x.size * int(sampling)
        x_interp = np.linspace(x[0], x[-1], n)
        y_interp = splev(x_interp, tck)
        y_der1 = splev(x_interp, tck, der=1)

        # identify peak:
        i = np.argmax(y_interp)

        # maximum at data edge, no peak found:
        if i + 1 == n or i == 0:
            return [], []

        # interpolate peak position:
        f = interp1d(y_der1[i-1:i+2], x_interp[i-1:i+2])
        peak_x = float(f(0))
        peak_y = float(splev(peak_x, tck))

        # find left peak edge:
        i = np.argmax(y)
        peak_max = peak_y
        n = x.size
        for n in range(i+1, x.size):
            if y[n] &lt; peak_max:
                peak_max = y[n]
            else:
                break

        # find right peak edge:
        peak_max = peak_y
        m = 0
        for m in range(i-1, 0, -1):
            if y[m] &lt; peak_max:
                peak_max = y[m]
            else:
                break

        peak_x = [peak_x]
        peak_y = [peak_y]

        # recursion on left part:
        if m &gt; 1 and np.any(y[:m] &gt; threshold):
            peak_x_l, peak_y_l = self._find_peaks(
                    x[:m], y[:m], threshold, sampling=sampling)
            peak_x = peak_x_l + peak_x
            peak_y = peak_y_l + peak_y

        # recursion on right part:
        if n &lt; x.size-1 and np.any(y[n:] &gt; threshold):
            peak_x_r, peak_y_r = self._find_peaks(
                    x[n:], y[n:], threshold, sampling=sampling)
            peak_x = peak_x + peak_x_r
            peak_y = peak_y + peak_y_r

        return peak_x, peak_y

    #--------------------------------------------------------------------------
    def find_peaks(
            self, signal, quantile, sampling=10, period_space=None,
            verbose=True):
        &#34;&#34;&#34;Find peaks along frequency/period in a given signal for all time
        bins.

        Parameters
        ----------
        signal : string
            Select &#39;wwz&#39; or &#39;wwa&#39;.
        quantile : float
            Defines the noise level. Only signals above the threshold are
            detected that corresponds to the set quantile.
        sampling : int
            The interpolated signal is evalued at n times the sampling of the
            original data, where n is set by this number.
        verbose : bool, optional
            Turns printing of information on or off. The default is True.

        Raises
        ------
        ValueError
            Raised when &#39;signal&#39; is not set to one of the allow values.

        Returns
        -------
        peak_tau : numpy.ndarray
            Time bins with detected signal above the threshold.
        peak_freq : numpy.ndarray
            Peak position, i.e. either frequency or period, depending on
            whether
            peak_ : numpy.ndarray

        Notes
        -----
        This method iterates through all time bins. The peak identification is
        implemented in the helper method self._find_peak().

        TBD
        ----
        Analysis of the p-values is currently turned off. The current peak
        location algorith does not work with flat p-value curves, due to an
        insufficient number of simulations.
        &#34;&#34;&#34;

        # TODO: p-value analysis deactivated because it is running into bugs.

        peak_tau = []
        peak_pos = []
        peak_signal = []

        # select signal for analysis:
        if signal not in [&#39;wwa&#39;, &#39;wwz&#39;]:
            raise ValueError(
                    &#34;For &#39;signal&#39; select &#39;wwz&#39; or &#39;wwa&#39;.&#34;)
        y = eval(f&#39;self.{signal}&#39;)

        # invert p-values:
        if signal.find(&#39;pval&#39;) &gt; -1:
            y = 1. - y

        # set threshold for signal detection:
        threshold = np.quantile(y, quantile)

        if verbose:
            print(&#39;Finding peaks in {0:s}.&#39;.format(signal.upper()))
            print(f&#39;Threshold set to: {threshold}&#39;)

        if (period_space is None and self.linear_period) or period_space:
            x = 1. / self.freq[::-1]
            y = y.transpose()[::-1].transpose()
            if verbose:
                print(&#39;Analysis in period space.&#39;)
        else:
            x = self.freq
            if verbose:
                print(&#39;Analysis in frequency space.&#39;)

        for i, t in enumerate(self.tau):
            peak_x, peak_y = self._find_peaks(
                    x, y[i], threshold, sampling=sampling)
            for px, py in zip(peak_x, peak_y):
                peak_tau.append(t)
                peak_pos.append(px)
                peak_signal.append(py)

        peak_tau = np.array(peak_tau)
        peak_pos = np.array(peak_pos)
        peak_signal = np.array(peak_signal)

        if verbose:
            print(&#39;Done.&#39;)

        return peak_tau, peak_pos, peak_signal

#==============================================================================</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="wwz.wwz.WWZ"><code class="flex name class">
<span>class <span class="ident">WWZ</span></span>
<span>(</span><span>time=None, flux=None, flux_err=0)</span>
</code></dt>
<dd>
<div class="desc"><p>A class for weighted wavelet z-transform analysis.</p>
<p>A class for weighted wavelet z-transform analysis.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>time</code></strong> :&ensp;<code>array-like</code>, optional</dt>
<dd>Time stamps of the input data. The default is None.</dd>
<dt><strong><code>flux</code></strong> :&ensp;<code>array-like</code>, optional</dt>
<dd>Flux of the input data. The default is None.</dd>
<dt><strong><code>flux_err</code></strong> :&ensp;<code>array-like</code> or <code>float</code>, optional</dt>
<dd>Flux uncertainty of the input data. The default is 0.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None.</p>
<h2 id="notes">Notes</h2>
<p>Setting the data during the instance initialization is optional. Data
can be provided with the set_data() method.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class WWZ:
    &#34;&#34;&#34;A class for weighted wavelet z-transform analysis.&#34;&#34;&#34;

    #--------------------------------------------------------------------------
    def __init__(self, time=None, flux=None, flux_err=0):
        &#34;&#34;&#34;A class for weighted wavelet z-transform analysis.

        Parameters
        ----------
        time : array-like, optional
            Time stamps of the input data. The default is None.
        flux : array-like, optional
            Flux of the input data. The default is None.
        flux_err : array-like or float, optional
            Flux uncertainty of the input data. The default is 0.

        Returns
        -------
        None.

        Notes
        -----
        Setting the data during the instance initialization is optional. Data
        can be provided with the set_data() method.
        &#34;&#34;&#34;

        print(&#39;WWZ instance created.&#39;)

        if time is not None and flux is not None:
            self.set_data(time, flux, flux_err=flux_err)
        else:
            self._reset()

    #--------------------------------------------------------------------------
    def _reset(self):
        &#34;&#34;&#34;Reset all class attributes to None.

        Returns
        -------
        None.
        &#34;&#34;&#34;

        # data time, flux, and flux error:
        self.t = None
        self.x = None
        self.s_x = None

        # number of data points:
        self.n = 0

        # attributes filled by set_freq() and set_tau():
        self.linear_period = False
        self.freq = None
        self.tau = None
        self.len0 = None
        self.len1 = None

        # class attributes filled by transform method:
        self.snr_weights = None
        self.c = None
        self.v_x = None
        self.v_y = None
        self.n_eff = None
        self.wwz = None
        self.wwa = None
        self.wwz_sig = None
        self.wwa_sig = None
        self.wwz_pval = None
        self.wwa_pval = None
        self.n_sig = None

    #--------------------------------------------------------------------------
    def set_data(self, time, flux, flux_err=0.0, verbose=True):
        &#34;&#34;&#34;Provide data for the analysis.

        Parameters
        ----------
        time : array-like, optional
            Time stamps of the input data. The default is None.
        flux : array-like, optional
            Flux of the input data. The default is None.
        flux_err : array-like or float, optional
            Flux uncertainty of the input data. The default is 0.
        verbose : bool, optional
            Turns printing of information on or off. The default is True.

        Returns
        -------
        None.

        Notes
        -----
        When new data is provided all class attributes that may contain the
        results of an earlier analysis will be reset to None.
        &#34;&#34;&#34;

        self._reset()

        # data time, flux, and flux error:
        self.t = np.asarray(time)
        self.x = np.asarray(flux)
        self.s_x = np.asarray(flux_err)

        # number of data points:
        self.n = len(time)

        if verbose:
            print(&#39;Data stored.&#39;)

    #--------------------------------------------------------------------------
    def get_period_lims(self, p_min_factor=4., p_max_factor=5.):
        &#34;&#34;&#34;Get suggested limits for the periods.

        Parameters
        ----------
        p_min_factor : float, optional
            If p_min is None, p_min is calculated as the median difference
            between time steps multiplied with this factor.
        p_max_factor : float, optional
            If p_max is None, p_max is calculated as the total time of the data
            devided by this factor.

        Returns
        -------
        p_min : float
            Suggested minimum period.
        p_max : float
            Suggested maximum period.
        &#34;&#34;&#34;

        p_min = np.round(np.median(np.diff(self.t)) * p_min_factor)
        p_max = np.round((self.t[-1] - self.t[0]) / p_max_factor)

        return p_min, p_max

    #--------------------------------------------------------------------------
    def get_freq(
            self, p_min=None, p_max=None, n_bins=100, diff=None,
            linear_period=False, p_min_factor=4., p_max_factor=5.):
        &#34;&#34;&#34;Create a range of frequencies for the analysis.

        Parameters
        ----------
        p_min : float, optional
            Minimum period. If provided, this shorest period will define the
            highest frequency. If None, the shortest period will be determined
            by the median of the time difference between data points. The
            default is None.
        p_max : float, optional
            Maximum period. If provided, this largest period will define the
            lowest frequency. If None, the largest period will be determined
            by the total duration of the data. The default is None.
        n_bins : int, optional
            Number of frequencies. The default is 100.
        diff : float, optional
            Sets the difference between frequency bins. The number of bins will
            be calculated accordingly. If linear_period=True, this sets the
            difference between periods. If diff is set, this overwrites any
            input to n_bins. The default is None.
        linear_period : bool, optional
            If False, the frequencies will be distributed in equal steps. If
            True, the frequencies are chosen such that the corresponding
            periods are distributed in equal steps. The default is False.
        p_min_factor : float, optional
            If p_min is None, p_min is calculated as the median difference
            between time steps multiplied with this factor.
        p_max_factor : float, optional
            If p_max is None, p_max is calculated as the total time of the data
            devided by this factor.

        Raises
        ------
        ValueError
            Error is raise when neither n_bins nor diff is provided.

        Returns
        -------
        freq : numpy.ndarray
            One dimensional array of frequencies.
        &#34;&#34;&#34;

        p_min_suggested, p_max_suggested =  self.get_period_lims(
                p_min_factor=p_min_factor, p_max_factor=p_max_factor)

        if p_min is None:
            p_min = p_min_suggested
        elif p_min &lt; p_min_suggested:
            print(&#39;WARNING: p_min is shorter than {0} &#39;.format(p_min_factor),
                  &#39;times the median time step of the data.\np_min should &#39;,
                  &#39;not be shorter than {0}.\n&#39;.format(p_min_suggested))

        if p_max is None:
            p_max = p_max_suggested
        elif p_max &gt; p_max_suggested:
            print(&#39;WARNING: p_max is larger than the maximum time range&#39;,
                  &#39;of the data devided by {0}.\np_min &#39;.format(p_max_factor),
                  &#39;should not be larger than {0}.\n&#39;.format(p_max_suggested))

        freq_min = 1. / p_max
        freq_max = 1. / p_min

        if linear_period:
            if diff is not None:
                period = np.arange(p_min, p_max, diff)

            elif isinstance(n_bins, int):
                period = np.linspace(p_min, p_max, n_bins)
                diff = period[1] - period[0]

            else:
                raise ValueError(&#34;Either n_bins or diff needs to be set.&#34;)

            freq = 1. / period
            freq = freq[::-1]

        else:
            if diff is not None:
                freq = np.arange(freq_min, freq_max, diff)

            elif isinstance(n_bins, int):
                freq = np.linspace(freq_min, freq_max, n_bins)
                diff = freq[1] - freq[0]

            else:
                raise ValueError(&#34;Either n_bins or diff needs to be set.&#34;)

        print(&#39;Linear range of frequencies created with&#39;)
        print(&#39;Shortest period:       {0:10.2e}&#39;.format(p_min))
        print(&#39;Longest period:        {0:10.2e}&#39;.format(p_max))
        if linear_period:
            print(&#39;Period interval:       {0:10.2e}&#39;.format(diff))
        else:
            print(&#39;Period interval:       non-linear&#39;)
        print(&#39;Lowest frequency:      {0:10.2e}&#39;.format(freq_min))
        print(&#39;Highest frequency:     {0:10.2e}&#39;.format(freq_max))
        if linear_period:
            print(&#39;Frequency interval:    non-linear&#39;)
        else:
            print(&#39;Frequency interval:    {0:10.2e}&#39;.format(diff))
        print(&#39;Number of frequencies: {0:10d}\n&#39;.format(freq.size))

        return freq

    #--------------------------------------------------------------------------
    def get_tau(self, t_min=None, t_max=None, n_div=8, n_bins=None, dtau=None):
        &#34;&#34;&#34;Create a range of taus (time points) for the analysis.

        Parameters
        ----------
        t_min : float, optional
            Earliest time point. If not provided, will be the first data point.
            The default is None.
        t_max : float, optional
            Latest time point. If not provided, will be the last data point.
            The default is None.
        n_div : int, optional
            The total time of the data will be devided by n_div. The result is
            converted to the nearest integer. This sets the number of time
            bins. A larger n_div will result in fewer time bins, and vice
            versa. The default is 8.
        n_bins : int, optional
            Number of time bins. If n_bins is set, this overwrites any input to
            n_div. The default is None.
        dtau : float, optional
            Sets the difference between time bins. The number of bins will
            be calculated accordingly. If diff is set, this overwrites any
            input to n_bins and n_div. The default is None.

        Raises
        ------
        ValueError
            Error is raise when neither n_bins nor diff is provided.

        Returns
        -------
        freq : numpy.ndarray
            One dimensional array of frequencies.
        &#34;&#34;&#34;

        t_min = self.t[0]
        t_max = self.t[-1]

        if dtau is not None:
            tau = np.arange(t_min, t_max, dtau)
            n_bins = tau.size

        elif isinstance(n_bins, int):
            tau = np.linspace(t_min, t_max, n_bins)
            dtau = tau[1] - tau[0]

        elif isinstance(n_div, int):
            n_bins = int((t_max - t_min) / n_div)
            tau = np.linspace(t_min, t_max, n_bins)
            dtau = tau[1] - tau[0]

        else:
            raise ValueError(&#34;Either n_div, n_bins, or dtau needs to be set.&#34;)

        print(&#39;Linear range of tau (time points) created with&#39;)
        print(&#39;Earliest time:         {0:10.1f}&#39;.format(t_min))
        print(&#39;Latest time:           {0:10.1f}&#39;.format(t_max))
        print(&#39;Time interval:         {0:10.1f}&#39;.format(dtau))
        print(&#39;Points in time:        {0:10d}\n&#39;.format(n_bins))

        return tau

    #--------------------------------------------------------------------------
    def set_freq(self, freq, verbose=True):
        &#34;&#34;&#34;Set the frequencies for the analysis.

        Parameters
        ----------
        freq : array-like
            A range of frequencies at which the WWZ transform will be
            calculated.
        verbose : bool, optional
            Turns printing of information on or off. The default is True.

        Returns
        -------
        None.

        Notes
        -----
        It is recommended to use the get_freq() method to create the array of
        frequencies.
        &#34;&#34;&#34;

        self.freq = np.asarray(freq)
        self.len1 = freq.size

        # check if frequencies are linear in period space:
        dperiod = np.diff(1. / freq)
        self.linear_period = np.all(np.isclose(dperiod, dperiod[0]))

        if verbose:
            print(&#39;Frequencies set.&#39;)

    #--------------------------------------------------------------------------
    def set_tau(self, tau, verbose=True):
        &#34;&#34;&#34;Set the taus (time points) for the analysis.

        Parameters
        ----------
        tau : array-like
            A range of time points at which the WWZ transform will be
            calculated.
        verbose : bool, optional
            Turns printing of information on or off. The default is True.

        Returns
        -------
        None.

        Notes
        -----
        It is recommended to use the get_tau() method to create the array of
        taus.
        &#34;&#34;&#34;

        self.tau = np.asarray(tau)
        self.len0 = tau.size

        if verbose:
            print(&#39;Tau (time points) set.&#39;)

    #--------------------------------------------------------------------------
    def transform(self, c=1./(8.*np.pi**2), snr_weights=False, verbose=0):
        &#34;&#34;&#34;Perform the WWZ transform as defined in [1].

        Parameters
        ----------
        c : float, optional
            The window decay parameter. See [1], Sec. 1 for a description.
            The default is 1./(8.*np.pi**2).
        snr_weights : bool, optional
            If True, the fluxes are additionally weighted by their
            corresponding signal-to-noise ratio, derived from the provided
            flux uncertainties. The default is False.
        verbose : int, optional
            Defines how much information is printed out. 0, no information is
            printed. 1, some information is printed. 2, all information is
            printed. The default is 0.

        Returns
        -------
        bool
            Returns True, if the analysis was performed succesfully. False,
            otherwise.

        References
        ----------
        [1] Foster, 1996
            https://ui.adsabs.harvard.edu/abs/1996AJ....112.1709F/abstract

        &#34;&#34;&#34;

        if self.freq is None or self.tau is None:
            print(&#39;Frequencies and/or taus are not set. Analysis aborted.&#39;)
            return False

        if verbose:
            t_start = datetime.now()
            print(&#39;Starting the WWZ transform..&#39;)

        self.c = c
        self.snr_weights = snr_weights

        if verbose &gt; 1:
            print(&#39;Setting frequency-tau-grid..&#39;)

        # create the wavelet grid:
        freq, tau = np.meshgrid(2*np.pi*self.freq, self.tau)
        # freq: the frequencies at which to evaluate the wavelet
        # tau: the delays over which to calculate the wavelet

        if verbose &gt; 1:
            print(&#39;Creating weights..&#39;)

        # arrays which are used but not returned
        s = np.zeros((3, 3, self.len0, self.len1), dtype=np.float64)
        s_inv = np.zeros((3, 3, self.len0, self.len1), dtype=np.float64)
        w = np.zeros((self.n, self.len0, self.len1), dtype=np.float64)

        p1=0.0
        p2=0.0
        p3=0.0
        w_d=0.0
        w_d_s=0.0
        v_x=0.0
        v_x_s=0.0
        v_y=0.0
        v_y_s=0.0

        if verbose &gt; 1:
            print(&#39;Calculating projections and scattering matrix..&#39;)

        for a in np.arange(0, self.n):
            # weights:
            w[a] = np.exp(-self.c * freq**2 * (self.t[a] - tau)**2)

            if snr_weights:
                w[a] *= np.sqrt(self.x[a]**2 / self.s_x[a]**2)

            w_d += w[a]
            w_d_s += w[a]**2

            # weighted variation of the data:
            v_x += w[a] * self.x[a]
            v_x_s += w[a] * self.x[a]**2

            # trial functions:
            t1 = 1.0
            t2 = np.cos(freq * (self.t[a] - tau))
            t3 = np.sin(freq * (self.t[a] - tau))

            # projections:
            p1 += w[a] * t1 * self.x[a]
            p2 += w[a] * t2 * self.x[a]
            p3 += w[a] * t3 * self.x[a]

            # s-matrix elements:
            s[0,0] += w[a] * t1 * t1
            s[1,0] += w[a] * t2 * t1
            s[0,1] += w[a] * t1 * t2
            s[2,0] += w[a] * t3 * t1
            s[0,2] += w[a] * t1 * t3
            s[1,1] += w[a] * t2 * t2
            s[2,1] += w[a] * t3 * t2
            s[1,2] += w[a] * t2 * t3
            s[2,2] += w[a] * t3 * t3

        # the projections of the trial functions onto the data are:
        p1 /= w_d
        p2 /= w_d
        p3 /= w_d
        # the scattering matrix elements are:
        s /= w_d

        if verbose &gt; 1:
            print(&#39;Inverting scattering matrix..&#39;)

        # invert scattering matrix:
        for m in np.arange(0, self.len0):
            for n in np.arange(0, self.len1):
                s_inv[:,:,m,n] = np.linalg.inv(s[:,:,m,n])

        if verbose &gt; 1:
            print(&#39;Calculating model coefficients..&#39;)

        # model coefficients:
        y1 = s_inv[0,0] * p1 + s_inv[0,1] * p2 + s_inv[0,2] * p3
        y2 = s_inv[1,0] * p1 + s_inv[1,1] * p2 + s_inv[1,2] * p3
        y3 = s_inv[2,0] * p1 + s_inv[2,1] * p2 + s_inv[2,2] * p3

        if verbose &gt; 1:
            print(&#39;Calculating elements of transform..&#39;)

        # calculate elements of the transform:
        for a in np.arange(self.n):
            ya = y1 * 1.0 + y2 * np.cos(freq * (self.t[a] - tau)) \
                    + y3 * np.sin(freq * (self.t[a] - tau))
            v_y += w[a] * ya
            v_y_s += w[a] * ya**2

        if verbose &gt; 1:
            print(&#39;Calculating WWZ and WWA..&#39;)

        self.v_x = (v_x_s / w_d) - (v_x / w_d)**2
        self.v_y = (v_y_s / w_d) - (v_y / w_d)**2
        self.n_eff = w_d**2 / w_d_s
        self.wwz = ((self.n_eff - 3.) * self.v_y) \
                / (2. * (self.v_x - self.v_y))
        self.wwa = np.sqrt(y2**2 + y3**2)

        if verbose:
            t_used = datetime.now() - t_start
            print(&#39;Finished in&#39;, t_used)

        return True

    #--------------------------------------------------------------------------
    def save(self, filename):
        &#34;&#34;&#34;Save the class instance in a python pickle file.

        Parameters
        ----------
        filename : str
            Filename under which the class instance is saved.

        Returns
        -------
        None.
        &#34;&#34;&#34;

        with open(filename, mode=&#39;wb&#39;) as f:
            pickle.dump(self, f)

    #--------------------------------------------------------------------------
    def load(self, filename):
        &#34;&#34;&#34;Load a saved WWZ class instance from a python pickle file.

        Parameters
        ----------
        filename : str
            File name of the pickle file.

        Returns
        -------
        WWZ-type
            Returns a instance of WWZ.
        &#34;&#34;&#34;

        with open(filename, mode=&#39;rb&#39;) as f:
            return pickle.load(f)

    #--------------------------------------------------------------------------
    def estimate_significance(self, simulations, append=False):
        &#34;&#34;&#34;Monte Carlo based significance estimation.

        Parameters
        ----------
        simulations : list
            Each list entry is one simulation that will be analysed in the same
            way as the real data. The data structure for each simulation need
            to be the following. A list, tuple, or numpy.ndarray, where the
            first element/row contains the time steps, the second element/row
            contains the signal. Optionally a third element contains the
            corresponding uncertainties. The uncertainty can also be a single
            value.
        append : bool, optional
            If False, currently available significance estimations will be
            discarded and overwritten with the new analysis. If True, the
            analysis of the new simulations will be added to the existing ones.
            The default is False.

        Returns
        -------
        bool
            True, if the analysis finished. False, if the analysis was aborted.

        Notes
        -----
        When new simulations are appended, i.e. append=True, it is up to the
        user to ensure that the new simulations are independent of the previous
        ones. This method does not track simulations and cannot guarantee that
        repetitions are discarded.
        &#34;&#34;&#34;

        if self.wwz is None:
            print(&#39;Analyse data first. Aborted!&#39;)
            return False

        # reset/initialize simulation results:
        if not append or self.wwz_sig is None:
            self.wwz_sig = np.zeros(shape=self.wwz.shape)
            self.wwa_sig = np.zeros(shape=self.wwa.shape)
            self.n_sig = 0

        # prepare WWZ instance for analysis of simulations:
        analyser = WWZ()

        n = len(simulations)
        t_start = datetime.now()
        print(&#39;Starting analysis of simulations at&#39;, t_start)

        # iterate through simulations:
        for i, simulation in enumerate(simulations):
            sys.stdout.write(&#39;\rProgress: {0:d} of {1:d}. {2:.1f}%&#39;. format(
                    i+1, n, i*100./n))

            # extract simulation data:
            time = simulation[0]
            flux = simulation[1]
            try:
                flux_err = simulation[2]
            except:
                flux_err = 0

            # analyse simulation data:
            analyser.set_data(time, flux, flux_err, verbose=False)
            analyser.set_freq(self.freq, verbose=False)
            analyser.set_tau(self.tau, verbose=False)
            analyser.transform(
                    c=self.c, snr_weights=self.snr_weights, verbose=0)
            self.wwz_sig += analyser.wwz &gt; self.wwz
            self.wwa_sig += analyser.wwa &gt; self.wwa
            self.n_sig += 1

        self.wwz_pval = self.wwz_sig / self.n_sig
        self.wwa_pval = self.wwa_sig / self.n_sig

        t_used = datetime.now() - t_start
        print(&#39;\rFinished in&#39;, t_used)

        return True

    #--------------------------------------------------------------------------
    def _find_peaks(self, x, y, threshold, sampling=10):
        &#34;&#34;&#34;Find peaks above a given threshold along a 1d-signal y(x).

        Parameters
        ----------
        x : numpy.ndarray
            Positional data of the signal, e.g. frequency or period.
        y : numpy.ndarray
            Signal, e.g. WWZ, WWA, or p-value along one time bin.
        threshold : float
            Defines the noise level. Only signals above this threshold are
            detected.
        sampling : int
            The interpolated signal is evalued at n times the sampling of the
            original data, where n is set by this number.

        Returns
        -------
        peak_x : list
            Peak positions.
        peak_y : list
            Peak signal strenghts.

        Notes
        -----
        This method uses spline interpolation to improve the estimation of the
        peak position and signal. Multiple peaks are identified recursively
        starting with the strongest peak.
        &#34;&#34;&#34;

        if np.all(y &lt; threshold) or x.size &lt;= 3:
            return [], []

        # the spline fit requires an increasing order of x,
        # reverse order, if x is decreasing:
        if x.size &gt; 1 and x[0] &gt; x[1]:
            x = x[::-1]
            y = y[::-1]

        # spline interpolation:
        tck = splrep(x, y, s=0)
        n = x.size * int(sampling)
        x_interp = np.linspace(x[0], x[-1], n)
        y_interp = splev(x_interp, tck)
        y_der1 = splev(x_interp, tck, der=1)

        # identify peak:
        i = np.argmax(y_interp)

        # maximum at data edge, no peak found:
        if i + 1 == n or i == 0:
            return [], []

        # interpolate peak position:
        f = interp1d(y_der1[i-1:i+2], x_interp[i-1:i+2])
        peak_x = float(f(0))
        peak_y = float(splev(peak_x, tck))

        # find left peak edge:
        i = np.argmax(y)
        peak_max = peak_y
        n = x.size
        for n in range(i+1, x.size):
            if y[n] &lt; peak_max:
                peak_max = y[n]
            else:
                break

        # find right peak edge:
        peak_max = peak_y
        m = 0
        for m in range(i-1, 0, -1):
            if y[m] &lt; peak_max:
                peak_max = y[m]
            else:
                break

        peak_x = [peak_x]
        peak_y = [peak_y]

        # recursion on left part:
        if m &gt; 1 and np.any(y[:m] &gt; threshold):
            peak_x_l, peak_y_l = self._find_peaks(
                    x[:m], y[:m], threshold, sampling=sampling)
            peak_x = peak_x_l + peak_x
            peak_y = peak_y_l + peak_y

        # recursion on right part:
        if n &lt; x.size-1 and np.any(y[n:] &gt; threshold):
            peak_x_r, peak_y_r = self._find_peaks(
                    x[n:], y[n:], threshold, sampling=sampling)
            peak_x = peak_x + peak_x_r
            peak_y = peak_y + peak_y_r

        return peak_x, peak_y

    #--------------------------------------------------------------------------
    def find_peaks(
            self, signal, quantile, sampling=10, period_space=None,
            verbose=True):
        &#34;&#34;&#34;Find peaks along frequency/period in a given signal for all time
        bins.

        Parameters
        ----------
        signal : string
            Select &#39;wwz&#39; or &#39;wwa&#39;.
        quantile : float
            Defines the noise level. Only signals above the threshold are
            detected that corresponds to the set quantile.
        sampling : int
            The interpolated signal is evalued at n times the sampling of the
            original data, where n is set by this number.
        verbose : bool, optional
            Turns printing of information on or off. The default is True.

        Raises
        ------
        ValueError
            Raised when &#39;signal&#39; is not set to one of the allow values.

        Returns
        -------
        peak_tau : numpy.ndarray
            Time bins with detected signal above the threshold.
        peak_freq : numpy.ndarray
            Peak position, i.e. either frequency or period, depending on
            whether
            peak_ : numpy.ndarray

        Notes
        -----
        This method iterates through all time bins. The peak identification is
        implemented in the helper method self._find_peak().

        TBD
        ----
        Analysis of the p-values is currently turned off. The current peak
        location algorith does not work with flat p-value curves, due to an
        insufficient number of simulations.
        &#34;&#34;&#34;

        # TODO: p-value analysis deactivated because it is running into bugs.

        peak_tau = []
        peak_pos = []
        peak_signal = []

        # select signal for analysis:
        if signal not in [&#39;wwa&#39;, &#39;wwz&#39;]:
            raise ValueError(
                    &#34;For &#39;signal&#39; select &#39;wwz&#39; or &#39;wwa&#39;.&#34;)
        y = eval(f&#39;self.{signal}&#39;)

        # invert p-values:
        if signal.find(&#39;pval&#39;) &gt; -1:
            y = 1. - y

        # set threshold for signal detection:
        threshold = np.quantile(y, quantile)

        if verbose:
            print(&#39;Finding peaks in {0:s}.&#39;.format(signal.upper()))
            print(f&#39;Threshold set to: {threshold}&#39;)

        if (period_space is None and self.linear_period) or period_space:
            x = 1. / self.freq[::-1]
            y = y.transpose()[::-1].transpose()
            if verbose:
                print(&#39;Analysis in period space.&#39;)
        else:
            x = self.freq
            if verbose:
                print(&#39;Analysis in frequency space.&#39;)

        for i, t in enumerate(self.tau):
            peak_x, peak_y = self._find_peaks(
                    x, y[i], threshold, sampling=sampling)
            for px, py in zip(peak_x, peak_y):
                peak_tau.append(t)
                peak_pos.append(px)
                peak_signal.append(py)

        peak_tau = np.array(peak_tau)
        peak_pos = np.array(peak_pos)
        peak_signal = np.array(peak_signal)

        if verbose:
            print(&#39;Done.&#39;)

        return peak_tau, peak_pos, peak_signal</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="wwz.wwz.WWZ.estimate_significance"><code class="name flex">
<span>def <span class="ident">estimate_significance</span></span>(<span>self, simulations, append=False)</span>
</code></dt>
<dd>
<div class="desc"><p>Monte Carlo based significance estimation.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>simulations</code></strong> :&ensp;<code>list</code></dt>
<dd>Each list entry is one simulation that will be analysed in the same
way as the real data. The data structure for each simulation need
to be the following. A list, tuple, or numpy.ndarray, where the
first element/row contains the time steps, the second element/row
contains the signal. Optionally a third element contains the
corresponding uncertainties. The uncertainty can also be a single
value.</dd>
<dt><strong><code>append</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If False, currently available significance estimations will be
discarded and overwritten with the new analysis. If True, the
analysis of the new simulations will be added to the existing ones.
The default is False.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>True, if the analysis finished. False, if the analysis was aborted.</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>When new simulations are appended, i.e. append=True, it is up to the
user to ensure that the new simulations are independent of the previous
ones. This method does not track simulations and cannot guarantee that
repetitions are discarded.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def estimate_significance(self, simulations, append=False):
    &#34;&#34;&#34;Monte Carlo based significance estimation.

    Parameters
    ----------
    simulations : list
        Each list entry is one simulation that will be analysed in the same
        way as the real data. The data structure for each simulation need
        to be the following. A list, tuple, or numpy.ndarray, where the
        first element/row contains the time steps, the second element/row
        contains the signal. Optionally a third element contains the
        corresponding uncertainties. The uncertainty can also be a single
        value.
    append : bool, optional
        If False, currently available significance estimations will be
        discarded and overwritten with the new analysis. If True, the
        analysis of the new simulations will be added to the existing ones.
        The default is False.

    Returns
    -------
    bool
        True, if the analysis finished. False, if the analysis was aborted.

    Notes
    -----
    When new simulations are appended, i.e. append=True, it is up to the
    user to ensure that the new simulations are independent of the previous
    ones. This method does not track simulations and cannot guarantee that
    repetitions are discarded.
    &#34;&#34;&#34;

    if self.wwz is None:
        print(&#39;Analyse data first. Aborted!&#39;)
        return False

    # reset/initialize simulation results:
    if not append or self.wwz_sig is None:
        self.wwz_sig = np.zeros(shape=self.wwz.shape)
        self.wwa_sig = np.zeros(shape=self.wwa.shape)
        self.n_sig = 0

    # prepare WWZ instance for analysis of simulations:
    analyser = WWZ()

    n = len(simulations)
    t_start = datetime.now()
    print(&#39;Starting analysis of simulations at&#39;, t_start)

    # iterate through simulations:
    for i, simulation in enumerate(simulations):
        sys.stdout.write(&#39;\rProgress: {0:d} of {1:d}. {2:.1f}%&#39;. format(
                i+1, n, i*100./n))

        # extract simulation data:
        time = simulation[0]
        flux = simulation[1]
        try:
            flux_err = simulation[2]
        except:
            flux_err = 0

        # analyse simulation data:
        analyser.set_data(time, flux, flux_err, verbose=False)
        analyser.set_freq(self.freq, verbose=False)
        analyser.set_tau(self.tau, verbose=False)
        analyser.transform(
                c=self.c, snr_weights=self.snr_weights, verbose=0)
        self.wwz_sig += analyser.wwz &gt; self.wwz
        self.wwa_sig += analyser.wwa &gt; self.wwa
        self.n_sig += 1

    self.wwz_pval = self.wwz_sig / self.n_sig
    self.wwa_pval = self.wwa_sig / self.n_sig

    t_used = datetime.now() - t_start
    print(&#39;\rFinished in&#39;, t_used)

    return True</code></pre>
</details>
</dd>
<dt id="wwz.wwz.WWZ.find_peaks"><code class="name flex">
<span>def <span class="ident">find_peaks</span></span>(<span>self, signal, quantile, sampling=10, period_space=None, verbose=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Find peaks along frequency/period in a given signal for all time
bins.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>signal</code></strong> :&ensp;<code>string</code></dt>
<dd>Select 'wwz' or 'wwa'.</dd>
<dt><strong><code>quantile</code></strong> :&ensp;<code>float</code></dt>
<dd>Defines the noise level. Only signals above the threshold are
detected that corresponds to the set quantile.</dd>
<dt><strong><code>sampling</code></strong> :&ensp;<code>int</code></dt>
<dd>The interpolated signal is evalued at n times the sampling of the
original data, where n is set by this number.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Turns printing of information on or off. The default is True.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>Raised when 'signal' is not set to one of the allow values.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>peak_tau</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>Time bins with detected signal above the threshold.</dd>
<dt><strong><code>peak_freq</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>Peak position, i.e. either frequency or period, depending on
whether
peak_ : numpy.ndarray</dd>
</dl>
<h2 id="notes">Notes</h2>
<p>This method iterates through all time bins. The peak identification is
implemented in the helper method self._find_peak().</p>
<h2 id="tbd">Tbd</h2>
<p>Analysis of the p-values is currently turned off. The current peak
location algorith does not work with flat p-value curves, due to an
insufficient number of simulations.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_peaks(
        self, signal, quantile, sampling=10, period_space=None,
        verbose=True):
    &#34;&#34;&#34;Find peaks along frequency/period in a given signal for all time
    bins.

    Parameters
    ----------
    signal : string
        Select &#39;wwz&#39; or &#39;wwa&#39;.
    quantile : float
        Defines the noise level. Only signals above the threshold are
        detected that corresponds to the set quantile.
    sampling : int
        The interpolated signal is evalued at n times the sampling of the
        original data, where n is set by this number.
    verbose : bool, optional
        Turns printing of information on or off. The default is True.

    Raises
    ------
    ValueError
        Raised when &#39;signal&#39; is not set to one of the allow values.

    Returns
    -------
    peak_tau : numpy.ndarray
        Time bins with detected signal above the threshold.
    peak_freq : numpy.ndarray
        Peak position, i.e. either frequency or period, depending on
        whether
        peak_ : numpy.ndarray

    Notes
    -----
    This method iterates through all time bins. The peak identification is
    implemented in the helper method self._find_peak().

    TBD
    ----
    Analysis of the p-values is currently turned off. The current peak
    location algorith does not work with flat p-value curves, due to an
    insufficient number of simulations.
    &#34;&#34;&#34;

    # TODO: p-value analysis deactivated because it is running into bugs.

    peak_tau = []
    peak_pos = []
    peak_signal = []

    # select signal for analysis:
    if signal not in [&#39;wwa&#39;, &#39;wwz&#39;]:
        raise ValueError(
                &#34;For &#39;signal&#39; select &#39;wwz&#39; or &#39;wwa&#39;.&#34;)
    y = eval(f&#39;self.{signal}&#39;)

    # invert p-values:
    if signal.find(&#39;pval&#39;) &gt; -1:
        y = 1. - y

    # set threshold for signal detection:
    threshold = np.quantile(y, quantile)

    if verbose:
        print(&#39;Finding peaks in {0:s}.&#39;.format(signal.upper()))
        print(f&#39;Threshold set to: {threshold}&#39;)

    if (period_space is None and self.linear_period) or period_space:
        x = 1. / self.freq[::-1]
        y = y.transpose()[::-1].transpose()
        if verbose:
            print(&#39;Analysis in period space.&#39;)
    else:
        x = self.freq
        if verbose:
            print(&#39;Analysis in frequency space.&#39;)

    for i, t in enumerate(self.tau):
        peak_x, peak_y = self._find_peaks(
                x, y[i], threshold, sampling=sampling)
        for px, py in zip(peak_x, peak_y):
            peak_tau.append(t)
            peak_pos.append(px)
            peak_signal.append(py)

    peak_tau = np.array(peak_tau)
    peak_pos = np.array(peak_pos)
    peak_signal = np.array(peak_signal)

    if verbose:
        print(&#39;Done.&#39;)

    return peak_tau, peak_pos, peak_signal</code></pre>
</details>
</dd>
<dt id="wwz.wwz.WWZ.get_freq"><code class="name flex">
<span>def <span class="ident">get_freq</span></span>(<span>self, p_min=None, p_max=None, n_bins=100, diff=None, linear_period=False, p_min_factor=4.0, p_max_factor=5.0)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a range of frequencies for the analysis.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>p_min</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>Minimum period. If provided, this shorest period will define the
highest frequency. If None, the shortest period will be determined
by the median of the time difference between data points. The
default is None.</dd>
<dt><strong><code>p_max</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>Maximum period. If provided, this largest period will define the
lowest frequency. If None, the largest period will be determined
by the total duration of the data. The default is None.</dd>
<dt><strong><code>n_bins</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of frequencies. The default is 100.</dd>
<dt><strong><code>diff</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>Sets the difference between frequency bins. The number of bins will
be calculated accordingly. If linear_period=True, this sets the
difference between periods. If diff is set, this overwrites any
input to n_bins. The default is None.</dd>
<dt><strong><code>linear_period</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If False, the frequencies will be distributed in equal steps. If
True, the frequencies are chosen such that the corresponding
periods are distributed in equal steps. The default is False.</dd>
<dt><strong><code>p_min_factor</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>If p_min is None, p_min is calculated as the median difference
between time steps multiplied with this factor.</dd>
<dt><strong><code>p_max_factor</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>If p_max is None, p_max is calculated as the total time of the data
devided by this factor.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>Error is raise when neither n_bins nor diff is provided.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>freq</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>One dimensional array of frequencies.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_freq(
        self, p_min=None, p_max=None, n_bins=100, diff=None,
        linear_period=False, p_min_factor=4., p_max_factor=5.):
    &#34;&#34;&#34;Create a range of frequencies for the analysis.

    Parameters
    ----------
    p_min : float, optional
        Minimum period. If provided, this shorest period will define the
        highest frequency. If None, the shortest period will be determined
        by the median of the time difference between data points. The
        default is None.
    p_max : float, optional
        Maximum period. If provided, this largest period will define the
        lowest frequency. If None, the largest period will be determined
        by the total duration of the data. The default is None.
    n_bins : int, optional
        Number of frequencies. The default is 100.
    diff : float, optional
        Sets the difference between frequency bins. The number of bins will
        be calculated accordingly. If linear_period=True, this sets the
        difference between periods. If diff is set, this overwrites any
        input to n_bins. The default is None.
    linear_period : bool, optional
        If False, the frequencies will be distributed in equal steps. If
        True, the frequencies are chosen such that the corresponding
        periods are distributed in equal steps. The default is False.
    p_min_factor : float, optional
        If p_min is None, p_min is calculated as the median difference
        between time steps multiplied with this factor.
    p_max_factor : float, optional
        If p_max is None, p_max is calculated as the total time of the data
        devided by this factor.

    Raises
    ------
    ValueError
        Error is raise when neither n_bins nor diff is provided.

    Returns
    -------
    freq : numpy.ndarray
        One dimensional array of frequencies.
    &#34;&#34;&#34;

    p_min_suggested, p_max_suggested =  self.get_period_lims(
            p_min_factor=p_min_factor, p_max_factor=p_max_factor)

    if p_min is None:
        p_min = p_min_suggested
    elif p_min &lt; p_min_suggested:
        print(&#39;WARNING: p_min is shorter than {0} &#39;.format(p_min_factor),
              &#39;times the median time step of the data.\np_min should &#39;,
              &#39;not be shorter than {0}.\n&#39;.format(p_min_suggested))

    if p_max is None:
        p_max = p_max_suggested
    elif p_max &gt; p_max_suggested:
        print(&#39;WARNING: p_max is larger than the maximum time range&#39;,
              &#39;of the data devided by {0}.\np_min &#39;.format(p_max_factor),
              &#39;should not be larger than {0}.\n&#39;.format(p_max_suggested))

    freq_min = 1. / p_max
    freq_max = 1. / p_min

    if linear_period:
        if diff is not None:
            period = np.arange(p_min, p_max, diff)

        elif isinstance(n_bins, int):
            period = np.linspace(p_min, p_max, n_bins)
            diff = period[1] - period[0]

        else:
            raise ValueError(&#34;Either n_bins or diff needs to be set.&#34;)

        freq = 1. / period
        freq = freq[::-1]

    else:
        if diff is not None:
            freq = np.arange(freq_min, freq_max, diff)

        elif isinstance(n_bins, int):
            freq = np.linspace(freq_min, freq_max, n_bins)
            diff = freq[1] - freq[0]

        else:
            raise ValueError(&#34;Either n_bins or diff needs to be set.&#34;)

    print(&#39;Linear range of frequencies created with&#39;)
    print(&#39;Shortest period:       {0:10.2e}&#39;.format(p_min))
    print(&#39;Longest period:        {0:10.2e}&#39;.format(p_max))
    if linear_period:
        print(&#39;Period interval:       {0:10.2e}&#39;.format(diff))
    else:
        print(&#39;Period interval:       non-linear&#39;)
    print(&#39;Lowest frequency:      {0:10.2e}&#39;.format(freq_min))
    print(&#39;Highest frequency:     {0:10.2e}&#39;.format(freq_max))
    if linear_period:
        print(&#39;Frequency interval:    non-linear&#39;)
    else:
        print(&#39;Frequency interval:    {0:10.2e}&#39;.format(diff))
    print(&#39;Number of frequencies: {0:10d}\n&#39;.format(freq.size))

    return freq</code></pre>
</details>
</dd>
<dt id="wwz.wwz.WWZ.get_period_lims"><code class="name flex">
<span>def <span class="ident">get_period_lims</span></span>(<span>self, p_min_factor=4.0, p_max_factor=5.0)</span>
</code></dt>
<dd>
<div class="desc"><p>Get suggested limits for the periods.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>p_min_factor</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>If p_min is None, p_min is calculated as the median difference
between time steps multiplied with this factor.</dd>
<dt><strong><code>p_max_factor</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>If p_max is None, p_max is calculated as the total time of the data
devided by this factor.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>p_min</code></strong> :&ensp;<code>float</code></dt>
<dd>Suggested minimum period.</dd>
<dt><strong><code>p_max</code></strong> :&ensp;<code>float</code></dt>
<dd>Suggested maximum period.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_period_lims(self, p_min_factor=4., p_max_factor=5.):
    &#34;&#34;&#34;Get suggested limits for the periods.

    Parameters
    ----------
    p_min_factor : float, optional
        If p_min is None, p_min is calculated as the median difference
        between time steps multiplied with this factor.
    p_max_factor : float, optional
        If p_max is None, p_max is calculated as the total time of the data
        devided by this factor.

    Returns
    -------
    p_min : float
        Suggested minimum period.
    p_max : float
        Suggested maximum period.
    &#34;&#34;&#34;

    p_min = np.round(np.median(np.diff(self.t)) * p_min_factor)
    p_max = np.round((self.t[-1] - self.t[0]) / p_max_factor)

    return p_min, p_max</code></pre>
</details>
</dd>
<dt id="wwz.wwz.WWZ.get_tau"><code class="name flex">
<span>def <span class="ident">get_tau</span></span>(<span>self, t_min=None, t_max=None, n_div=8, n_bins=None, dtau=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Create a range of taus (time points) for the analysis.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>t_min</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>Earliest time point. If not provided, will be the first data point.
The default is None.</dd>
<dt><strong><code>t_max</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>Latest time point. If not provided, will be the last data point.
The default is None.</dd>
<dt><strong><code>n_div</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The total time of the data will be devided by n_div. The result is
converted to the nearest integer. This sets the number of time
bins. A larger n_div will result in fewer time bins, and vice
versa. The default is 8.</dd>
<dt><strong><code>n_bins</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of time bins. If n_bins is set, this overwrites any input to
n_div. The default is None.</dd>
<dt><strong><code>dtau</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>Sets the difference between time bins. The number of bins will
be calculated accordingly. If diff is set, this overwrites any
input to n_bins and n_div. The default is None.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>Error is raise when neither n_bins nor diff is provided.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><strong><code>freq</code></strong> :&ensp;<code>numpy.ndarray</code></dt>
<dd>One dimensional array of frequencies.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_tau(self, t_min=None, t_max=None, n_div=8, n_bins=None, dtau=None):
    &#34;&#34;&#34;Create a range of taus (time points) for the analysis.

    Parameters
    ----------
    t_min : float, optional
        Earliest time point. If not provided, will be the first data point.
        The default is None.
    t_max : float, optional
        Latest time point. If not provided, will be the last data point.
        The default is None.
    n_div : int, optional
        The total time of the data will be devided by n_div. The result is
        converted to the nearest integer. This sets the number of time
        bins. A larger n_div will result in fewer time bins, and vice
        versa. The default is 8.
    n_bins : int, optional
        Number of time bins. If n_bins is set, this overwrites any input to
        n_div. The default is None.
    dtau : float, optional
        Sets the difference between time bins. The number of bins will
        be calculated accordingly. If diff is set, this overwrites any
        input to n_bins and n_div. The default is None.

    Raises
    ------
    ValueError
        Error is raise when neither n_bins nor diff is provided.

    Returns
    -------
    freq : numpy.ndarray
        One dimensional array of frequencies.
    &#34;&#34;&#34;

    t_min = self.t[0]
    t_max = self.t[-1]

    if dtau is not None:
        tau = np.arange(t_min, t_max, dtau)
        n_bins = tau.size

    elif isinstance(n_bins, int):
        tau = np.linspace(t_min, t_max, n_bins)
        dtau = tau[1] - tau[0]

    elif isinstance(n_div, int):
        n_bins = int((t_max - t_min) / n_div)
        tau = np.linspace(t_min, t_max, n_bins)
        dtau = tau[1] - tau[0]

    else:
        raise ValueError(&#34;Either n_div, n_bins, or dtau needs to be set.&#34;)

    print(&#39;Linear range of tau (time points) created with&#39;)
    print(&#39;Earliest time:         {0:10.1f}&#39;.format(t_min))
    print(&#39;Latest time:           {0:10.1f}&#39;.format(t_max))
    print(&#39;Time interval:         {0:10.1f}&#39;.format(dtau))
    print(&#39;Points in time:        {0:10d}\n&#39;.format(n_bins))

    return tau</code></pre>
</details>
</dd>
<dt id="wwz.wwz.WWZ.load"><code class="name flex">
<span>def <span class="ident">load</span></span>(<span>self, filename)</span>
</code></dt>
<dd>
<div class="desc"><p>Load a saved WWZ class instance from a python pickle file.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>File name of the pickle file.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>WWZ-type</code></dt>
<dd>Returns a instance of WWZ.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load(self, filename):
    &#34;&#34;&#34;Load a saved WWZ class instance from a python pickle file.

    Parameters
    ----------
    filename : str
        File name of the pickle file.

    Returns
    -------
    WWZ-type
        Returns a instance of WWZ.
    &#34;&#34;&#34;

    with open(filename, mode=&#39;rb&#39;) as f:
        return pickle.load(f)</code></pre>
</details>
</dd>
<dt id="wwz.wwz.WWZ.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>self, filename)</span>
</code></dt>
<dd>
<div class="desc"><p>Save the class instance in a python pickle file.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>Filename under which the class instance is saved.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save(self, filename):
    &#34;&#34;&#34;Save the class instance in a python pickle file.

    Parameters
    ----------
    filename : str
        Filename under which the class instance is saved.

    Returns
    -------
    None.
    &#34;&#34;&#34;

    with open(filename, mode=&#39;wb&#39;) as f:
        pickle.dump(self, f)</code></pre>
</details>
</dd>
<dt id="wwz.wwz.WWZ.set_data"><code class="name flex">
<span>def <span class="ident">set_data</span></span>(<span>self, time, flux, flux_err=0.0, verbose=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Provide data for the analysis.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>time</code></strong> :&ensp;<code>array-like</code>, optional</dt>
<dd>Time stamps of the input data. The default is None.</dd>
<dt><strong><code>flux</code></strong> :&ensp;<code>array-like</code>, optional</dt>
<dd>Flux of the input data. The default is None.</dd>
<dt><strong><code>flux_err</code></strong> :&ensp;<code>array-like</code> or <code>float</code>, optional</dt>
<dd>Flux uncertainty of the input data. The default is 0.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Turns printing of information on or off. The default is True.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None.</p>
<h2 id="notes">Notes</h2>
<p>When new data is provided all class attributes that may contain the
results of an earlier analysis will be reset to None.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_data(self, time, flux, flux_err=0.0, verbose=True):
    &#34;&#34;&#34;Provide data for the analysis.

    Parameters
    ----------
    time : array-like, optional
        Time stamps of the input data. The default is None.
    flux : array-like, optional
        Flux of the input data. The default is None.
    flux_err : array-like or float, optional
        Flux uncertainty of the input data. The default is 0.
    verbose : bool, optional
        Turns printing of information on or off. The default is True.

    Returns
    -------
    None.

    Notes
    -----
    When new data is provided all class attributes that may contain the
    results of an earlier analysis will be reset to None.
    &#34;&#34;&#34;

    self._reset()

    # data time, flux, and flux error:
    self.t = np.asarray(time)
    self.x = np.asarray(flux)
    self.s_x = np.asarray(flux_err)

    # number of data points:
    self.n = len(time)

    if verbose:
        print(&#39;Data stored.&#39;)</code></pre>
</details>
</dd>
<dt id="wwz.wwz.WWZ.set_freq"><code class="name flex">
<span>def <span class="ident">set_freq</span></span>(<span>self, freq, verbose=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Set the frequencies for the analysis.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>freq</code></strong> :&ensp;<code>array-like</code></dt>
<dd>A range of frequencies at which the WWZ transform will be
calculated.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Turns printing of information on or off. The default is True.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None.</p>
<h2 id="notes">Notes</h2>
<p>It is recommended to use the get_freq() method to create the array of
frequencies.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_freq(self, freq, verbose=True):
    &#34;&#34;&#34;Set the frequencies for the analysis.

    Parameters
    ----------
    freq : array-like
        A range of frequencies at which the WWZ transform will be
        calculated.
    verbose : bool, optional
        Turns printing of information on or off. The default is True.

    Returns
    -------
    None.

    Notes
    -----
    It is recommended to use the get_freq() method to create the array of
    frequencies.
    &#34;&#34;&#34;

    self.freq = np.asarray(freq)
    self.len1 = freq.size

    # check if frequencies are linear in period space:
    dperiod = np.diff(1. / freq)
    self.linear_period = np.all(np.isclose(dperiod, dperiod[0]))

    if verbose:
        print(&#39;Frequencies set.&#39;)</code></pre>
</details>
</dd>
<dt id="wwz.wwz.WWZ.set_tau"><code class="name flex">
<span>def <span class="ident">set_tau</span></span>(<span>self, tau, verbose=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Set the taus (time points) for the analysis.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>tau</code></strong> :&ensp;<code>array-like</code></dt>
<dd>A range of time points at which the WWZ transform will be
calculated.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Turns printing of information on or off. The default is True.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>None.</p>
<h2 id="notes">Notes</h2>
<p>It is recommended to use the get_tau() method to create the array of
taus.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def set_tau(self, tau, verbose=True):
    &#34;&#34;&#34;Set the taus (time points) for the analysis.

    Parameters
    ----------
    tau : array-like
        A range of time points at which the WWZ transform will be
        calculated.
    verbose : bool, optional
        Turns printing of information on or off. The default is True.

    Returns
    -------
    None.

    Notes
    -----
    It is recommended to use the get_tau() method to create the array of
    taus.
    &#34;&#34;&#34;

    self.tau = np.asarray(tau)
    self.len0 = tau.size

    if verbose:
        print(&#39;Tau (time points) set.&#39;)</code></pre>
</details>
</dd>
<dt id="wwz.wwz.WWZ.transform"><code class="name flex">
<span>def <span class="ident">transform</span></span>(<span>self, c=0.012665147955292222, snr_weights=False, verbose=0)</span>
</code></dt>
<dd>
<div class="desc"><p>Perform the WWZ transform as defined in [1].</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>c</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>The window decay parameter. See [1], Sec. 1 for a description.
The default is 1./(8.<em>np.pi</em>*2).</dd>
<dt><strong><code>snr_weights</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If True, the fluxes are additionally weighted by their
corresponding signal-to-noise ratio, derived from the provided
flux uncertainties. The default is False.</dd>
<dt><strong><code>verbose</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Defines how much information is printed out. 0, no information is
printed. 1, some information is printed. 2, all information is
printed. The default is 0.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>bool</code></dt>
<dd>Returns True, if the analysis was performed succesfully. False,
otherwise.</dd>
</dl>
<h2 id="references">References</h2>
<p>[1] Foster, 1996
<a href="https://ui.adsabs.harvard.edu/abs/1996AJ....112.1709F/abstract">https://ui.adsabs.harvard.edu/abs/1996AJ....112.1709F/abstract</a></p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def transform(self, c=1./(8.*np.pi**2), snr_weights=False, verbose=0):
    &#34;&#34;&#34;Perform the WWZ transform as defined in [1].

    Parameters
    ----------
    c : float, optional
        The window decay parameter. See [1], Sec. 1 for a description.
        The default is 1./(8.*np.pi**2).
    snr_weights : bool, optional
        If True, the fluxes are additionally weighted by their
        corresponding signal-to-noise ratio, derived from the provided
        flux uncertainties. The default is False.
    verbose : int, optional
        Defines how much information is printed out. 0, no information is
        printed. 1, some information is printed. 2, all information is
        printed. The default is 0.

    Returns
    -------
    bool
        Returns True, if the analysis was performed succesfully. False,
        otherwise.

    References
    ----------
    [1] Foster, 1996
        https://ui.adsabs.harvard.edu/abs/1996AJ....112.1709F/abstract

    &#34;&#34;&#34;

    if self.freq is None or self.tau is None:
        print(&#39;Frequencies and/or taus are not set. Analysis aborted.&#39;)
        return False

    if verbose:
        t_start = datetime.now()
        print(&#39;Starting the WWZ transform..&#39;)

    self.c = c
    self.snr_weights = snr_weights

    if verbose &gt; 1:
        print(&#39;Setting frequency-tau-grid..&#39;)

    # create the wavelet grid:
    freq, tau = np.meshgrid(2*np.pi*self.freq, self.tau)
    # freq: the frequencies at which to evaluate the wavelet
    # tau: the delays over which to calculate the wavelet

    if verbose &gt; 1:
        print(&#39;Creating weights..&#39;)

    # arrays which are used but not returned
    s = np.zeros((3, 3, self.len0, self.len1), dtype=np.float64)
    s_inv = np.zeros((3, 3, self.len0, self.len1), dtype=np.float64)
    w = np.zeros((self.n, self.len0, self.len1), dtype=np.float64)

    p1=0.0
    p2=0.0
    p3=0.0
    w_d=0.0
    w_d_s=0.0
    v_x=0.0
    v_x_s=0.0
    v_y=0.0
    v_y_s=0.0

    if verbose &gt; 1:
        print(&#39;Calculating projections and scattering matrix..&#39;)

    for a in np.arange(0, self.n):
        # weights:
        w[a] = np.exp(-self.c * freq**2 * (self.t[a] - tau)**2)

        if snr_weights:
            w[a] *= np.sqrt(self.x[a]**2 / self.s_x[a]**2)

        w_d += w[a]
        w_d_s += w[a]**2

        # weighted variation of the data:
        v_x += w[a] * self.x[a]
        v_x_s += w[a] * self.x[a]**2

        # trial functions:
        t1 = 1.0
        t2 = np.cos(freq * (self.t[a] - tau))
        t3 = np.sin(freq * (self.t[a] - tau))

        # projections:
        p1 += w[a] * t1 * self.x[a]
        p2 += w[a] * t2 * self.x[a]
        p3 += w[a] * t3 * self.x[a]

        # s-matrix elements:
        s[0,0] += w[a] * t1 * t1
        s[1,0] += w[a] * t2 * t1
        s[0,1] += w[a] * t1 * t2
        s[2,0] += w[a] * t3 * t1
        s[0,2] += w[a] * t1 * t3
        s[1,1] += w[a] * t2 * t2
        s[2,1] += w[a] * t3 * t2
        s[1,2] += w[a] * t2 * t3
        s[2,2] += w[a] * t3 * t3

    # the projections of the trial functions onto the data are:
    p1 /= w_d
    p2 /= w_d
    p3 /= w_d
    # the scattering matrix elements are:
    s /= w_d

    if verbose &gt; 1:
        print(&#39;Inverting scattering matrix..&#39;)

    # invert scattering matrix:
    for m in np.arange(0, self.len0):
        for n in np.arange(0, self.len1):
            s_inv[:,:,m,n] = np.linalg.inv(s[:,:,m,n])

    if verbose &gt; 1:
        print(&#39;Calculating model coefficients..&#39;)

    # model coefficients:
    y1 = s_inv[0,0] * p1 + s_inv[0,1] * p2 + s_inv[0,2] * p3
    y2 = s_inv[1,0] * p1 + s_inv[1,1] * p2 + s_inv[1,2] * p3
    y3 = s_inv[2,0] * p1 + s_inv[2,1] * p2 + s_inv[2,2] * p3

    if verbose &gt; 1:
        print(&#39;Calculating elements of transform..&#39;)

    # calculate elements of the transform:
    for a in np.arange(self.n):
        ya = y1 * 1.0 + y2 * np.cos(freq * (self.t[a] - tau)) \
                + y3 * np.sin(freq * (self.t[a] - tau))
        v_y += w[a] * ya
        v_y_s += w[a] * ya**2

    if verbose &gt; 1:
        print(&#39;Calculating WWZ and WWA..&#39;)

    self.v_x = (v_x_s / w_d) - (v_x / w_d)**2
    self.v_y = (v_y_s / w_d) - (v_y / w_d)**2
    self.n_eff = w_d**2 / w_d_s
    self.wwz = ((self.n_eff - 3.) * self.v_y) \
            / (2. * (self.v_x - self.v_y))
    self.wwa = np.sqrt(y2**2 + y3**2)

    if verbose:
        t_used = datetime.now() - t_start
        print(&#39;Finished in&#39;, t_used)

    return True</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="wwz" href="index.html">wwz</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="wwz.wwz.WWZ" href="#wwz.wwz.WWZ">WWZ</a></code></h4>
<ul class="">
<li><code><a title="wwz.wwz.WWZ.estimate_significance" href="#wwz.wwz.WWZ.estimate_significance">estimate_significance</a></code></li>
<li><code><a title="wwz.wwz.WWZ.find_peaks" href="#wwz.wwz.WWZ.find_peaks">find_peaks</a></code></li>
<li><code><a title="wwz.wwz.WWZ.get_freq" href="#wwz.wwz.WWZ.get_freq">get_freq</a></code></li>
<li><code><a title="wwz.wwz.WWZ.get_period_lims" href="#wwz.wwz.WWZ.get_period_lims">get_period_lims</a></code></li>
<li><code><a title="wwz.wwz.WWZ.get_tau" href="#wwz.wwz.WWZ.get_tau">get_tau</a></code></li>
<li><code><a title="wwz.wwz.WWZ.load" href="#wwz.wwz.WWZ.load">load</a></code></li>
<li><code><a title="wwz.wwz.WWZ.save" href="#wwz.wwz.WWZ.save">save</a></code></li>
<li><code><a title="wwz.wwz.WWZ.set_data" href="#wwz.wwz.WWZ.set_data">set_data</a></code></li>
<li><code><a title="wwz.wwz.WWZ.set_freq" href="#wwz.wwz.WWZ.set_freq">set_freq</a></code></li>
<li><code><a title="wwz.wwz.WWZ.set_tau" href="#wwz.wwz.WWZ.set_tau">set_tau</a></code></li>
<li><code><a title="wwz.wwz.WWZ.transform" href="#wwz.wwz.WWZ.transform">transform</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.1</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>